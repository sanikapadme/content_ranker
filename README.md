
# RL Content Ranker Dashboard

A reinforcement learningâ€“based content ranking system with an interactive dashboard, CTR tracking, and persistent metrics storage.

---

## Project Structure
content_ranker/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ frontend.html # Web dashboard UI
â”‚ â”œâ”€â”€ main.py # FastAPI backend + API routes
â”‚ â”œâ”€â”€ ranker.py # RL logic (Bandit, Q-Learning, InMemoryStore)
â”‚ â”œâ”€â”€ schemas.py # Pydantic request/response schemas
â”‚ â”œâ”€â”€ stress_test.py # Script for high-load feedback simulation
â”‚
â”œâ”€â”€ simulation/
â”‚ â”œâ”€â”€ simulate_users.py # Virtual user feedback simulator
â”‚
â”œâ”€â”€ venv/ # Python virtual environment
â”œâ”€â”€ metrics_history.json # Persistent metrics storage
â”œâ”€â”€ locustfile.py # Locust load testing file
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ Dockerfile # Docker build configuration
â”œâ”€â”€ .gitignore # Git ignore list
â”œâ”€â”€ README.md # Project documentation



---

## Features
- Epsilon-Greedy Bandit + Q-Learning Agent ranking logic.
- Real-time Dashboard with Chart.js graphs.
- CTR Tracking (click-through rate) and average engagement.
- Persistent Metrics (saved to `metrics_history.json`).
- User Feedback (`ğŸ‘` = click, `ğŸ‘` = skip).
- Reset & Train Controls for experimentation.
- Stress Testing with `stress_test.py` and `simulate_users.py`.

---

## Installation

### 1. Clone repository

git clone <your-repo-url>
cd content_ranker
2. Set up Python environment

python -m venv venv
Activate environment:

Windows:


venv\Scripts\activate
Mac/Linux:
source venv/bin/activate

3. Install dependencies
pip install -r requirements.txt
Run Backend
uvicorn app.main:app --reload

Open Dashboard
http://127.0.0.1:8000

Usage
View ranked content in a table.

Click ğŸ‘ to simulate a click (positive reward).

Click ğŸ‘ to simulate a skip (negative reward).

Charts:
Average Engagement over time

CTR over time

Buttons:
Reset Order â†’ Clears order but keeps history.

Full Reset â†’ Wipes all data and reloads dummy content.

Train Now â†’ Trains Q-Learning agent from stored history.

Persistence
Engagement history and metrics are stored in metrics_history.json.

Data persists across server restarts.

Stress Testing
Run simulated feedback to see ranking adapt:


python app/stress_test.py
# OR
python simulation/simulate_users.py


